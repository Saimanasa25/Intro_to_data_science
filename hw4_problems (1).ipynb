{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede484aa",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "We load the `music_scaled.csv` dataset ([source](https://archive.ics.uci.edu/ml/datasets/Geographical+Original+of+Music#)). The dataset contains a sample of traditional songs from different cultures. Features F1 to F68 are quantitative summaries of the songs from audio analysis software. These features have been subject to standard scaling. They are stored as predictors in `X.` The latitudes of the countries from which the songs originate are stored as a target variable `y.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fd54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"music_scaled.csv\")\n",
    "X = data.iloc[:,:68]\n",
    "y = data[\"Latitude\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2502e44",
   "metadata": {},
   "source": [
    "Perform linear regression of `y` on `X` using `sklearn.linear_model.LinearRegression` and print the estimated coefficient for F1. Print out the estimated coefficients when the regressors consist of \n",
    "- F1 only; \n",
    "- F1 and F2 only; \n",
    "- F1, F2, and F3 only; \n",
    "- F1, F2, F3, ..., and F[k] only; \n",
    "- and F1, F2, F3, ..., F[k], ..., and F68. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39efff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 : 0.6597339500122643\n",
      "F1 to F2 : 1.6699230411781016\n",
      "F1 to F3 : 2.222157586667263\n",
      "F1 to F4 : 2.3244270430823453\n",
      "F1 to F5 : 2.26829798301279\n",
      "F1 to F6 : 2.845235192482387\n",
      "F1 to F7 : 3.332087022407628\n",
      "F1 to F8 : 3.356678940253311\n",
      "F1 to F9 : 3.269856765113629\n",
      "F1 to F10 : 3.3032316382785947\n",
      "F1 to F11 : 3.2920770604158665\n",
      "F1 to F12 : 3.3208903646389256\n",
      "F1 to F13 : 3.3475351294232696\n",
      "F1 to F14 : 3.326816214636578\n",
      "F1 to F15 : 3.2858976426461757\n",
      "F1 to F16 : 2.973623021072868\n",
      "F1 to F17 : 2.9332092426984255\n",
      "F1 to F18 : 5.019515373249264\n",
      "F1 to F19 : 6.364015712678724\n",
      "F1 to F20 : 4.998354920508972\n",
      "F1 to F21 : 6.3647781723039385\n",
      "F1 to F22 : 4.133694649943328\n",
      "F1 to F23 : 4.730007093894298\n",
      "F1 to F24 : 4.981488781036372\n",
      "F1 to F25 : 4.930128203655882\n",
      "F1 to F26 : 5.093094310749861\n",
      "F1 to F27 : 5.198479732315793\n",
      "F1 to F28 : 5.163328587511276\n",
      "F1 to F29 : 5.157666806840068\n",
      "F1 to F30 : 5.312941265441785\n",
      "F1 to F31 : 5.275584887832944\n",
      "F1 to F32 : 5.282177798563277\n",
      "F1 to F33 : 5.303313147474663\n",
      "F1 to F34 : 4.938899882391728\n",
      "F1 to F35 : 4.758449191095823\n",
      "F1 to F36 : 3.9207413566535663\n",
      "F1 to F37 : 3.979083895754759\n",
      "F1 to F38 : 3.655118322511155\n",
      "F1 to F39 : 2.546008346527581\n",
      "F1 to F40 : 2.4268589999435393\n",
      "F1 to F41 : 2.217108907773841\n",
      "F1 to F42 : 2.310249219251345\n",
      "F1 to F43 : 2.5288936609952635\n",
      "F1 to F44 : 2.577280845791651\n",
      "F1 to F45 : 2.5796880236719333\n",
      "F1 to F46 : 2.7779106469450436\n",
      "F1 to F47 : 2.778351298560435\n",
      "F1 to F48 : 2.750938877211331\n",
      "F1 to F49 : 2.6242632787682405\n",
      "F1 to F50 : 2.6138196979310924\n",
      "F1 to F51 : 2.802340330013344\n",
      "F1 to F52 : 2.7307150553842354\n",
      "F1 to F53 : 5.263762169774711\n",
      "F1 to F54 : 6.424379996059415\n",
      "F1 to F55 : 8.821811756194727\n",
      "F1 to F56 : 9.162811807827783\n",
      "F1 to F57 : 8.983054742030507\n",
      "F1 to F58 : 8.984069782543193\n",
      "F1 to F59 : 8.619819631274382\n",
      "F1 to F60 : 8.961607071015836\n",
      "F1 to F61 : 8.991982928633368\n",
      "F1 to F62 : 8.923925522497674\n",
      "F1 to F63 : 8.864724445412252\n",
      "F1 to F64 : 8.697396597129599\n",
      "F1 to F65 : 8.636579698214177\n",
      "F1 to F66 : 8.896444495901148\n",
      "F1 to F67 : 8.45382033164654\n",
      "F1 to F68 : 8.303670971591531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "i=1\n",
    "info='F1'\n",
    "while i < len(X):\n",
    "    X_= X.iloc[:,:i]\n",
    "    reg = LinearRegression().fit(X_, y) #fit linear regression\n",
    "    reg_=reg.coef_\n",
    "    print(info,\":\",reg_[0])\n",
    "    \n",
    "    info = f'F1 to F{i+1}'\n",
    "    i += 1\n",
    "    if i == 69:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9524d597",
   "metadata": {},
   "source": [
    "Compute a full set of principal components of `X` using `sklearn.decomposition.PCA.` Perform linear regression of `y` on the PCs using `sklearn.linear_model.LinearRegression` and print the estimated coefficient for PC1. Print out the estimated coefficients when the regressors consist of \n",
    "- PC1 only; \n",
    "- PC1 and PC2 only; \n",
    "- PC1, PC2, and PC3 only;\n",
    "- PC1, PC2, PC3, ..., and PC[k] only; \n",
    "- and PC1, PC2, PC3, ..., PC[k], ..., and PC68. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9a6879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA1 : -0.08259022735453067\n",
      "PCA1 to PCA2 : -0.08259022735453067\n",
      "PCA1 to PCA3 : -0.08259022735453067\n",
      "PCA1 to PCA4 : -0.08259022735453067\n",
      "PCA1 to PCA5 : -0.08259022735453067\n",
      "PCA1 to PCA6 : -0.08259022735453067\n",
      "PCA1 to PCA7 : -0.08259022735453067\n",
      "PCA1 to PCA8 : -0.08259022735453067\n",
      "PCA1 to PCA9 : -0.08259022735453077\n",
      "PCA1 to PCA10 : -0.08259022735453077\n",
      "PCA1 to PCA11 : -0.08259022735453077\n",
      "PCA1 to PCA12 : -0.08259022735453077\n",
      "PCA1 to PCA13 : -0.08259022735453077\n",
      "PCA1 to PCA14 : -0.08259022735453077\n",
      "PCA1 to PCA15 : -0.08259022735453077\n",
      "PCA1 to PCA16 : -0.08259022735453077\n",
      "PCA1 to PCA17 : -0.08259022735453063\n",
      "PCA1 to PCA18 : -0.08259022735453063\n",
      "PCA1 to PCA19 : -0.08259022735453063\n",
      "PCA1 to PCA20 : -0.08259022735453063\n",
      "PCA1 to PCA21 : -0.08259022735453063\n",
      "PCA1 to PCA22 : -0.08259022735453063\n",
      "PCA1 to PCA23 : -0.08259022735453063\n",
      "PCA1 to PCA24 : -0.08259022735453063\n",
      "PCA1 to PCA25 : -0.08259022735453063\n",
      "PCA1 to PCA26 : -0.08259022735453041\n",
      "PCA1 to PCA27 : -0.08259022735453042\n",
      "PCA1 to PCA28 : -0.08259022735453042\n",
      "PCA1 to PCA29 : -0.08259022735453043\n",
      "PCA1 to PCA30 : -0.08259022735453041\n",
      "PCA1 to PCA31 : -0.08259022735453046\n",
      "PCA1 to PCA32 : -0.08259022735453045\n",
      "PCA1 to PCA33 : -0.08259022735453045\n",
      "PCA1 to PCA34 : -0.08259022735453045\n",
      "PCA1 to PCA35 : -0.08259022735453045\n",
      "PCA1 to PCA36 : -0.08259022735453045\n",
      "PCA1 to PCA37 : -0.08259022735453045\n",
      "PCA1 to PCA38 : -0.08259022735453045\n",
      "PCA1 to PCA39 : -0.08259022735453045\n",
      "PCA1 to PCA40 : -0.08259022735453046\n",
      "PCA1 to PCA41 : -0.08259022735453043\n",
      "PCA1 to PCA42 : -0.08259022735453045\n",
      "PCA1 to PCA43 : -0.08259022735453045\n",
      "PCA1 to PCA44 : -0.08259022735453043\n",
      "PCA1 to PCA45 : -0.08259022735453046\n",
      "PCA1 to PCA46 : -0.0825902273545305\n",
      "PCA1 to PCA47 : -0.08259022735453049\n",
      "PCA1 to PCA48 : -0.08259022735453048\n",
      "PCA1 to PCA49 : -0.08259022735453046\n",
      "PCA1 to PCA50 : -0.08259022735453048\n",
      "PCA1 to PCA51 : -0.08259022735453048\n",
      "PCA1 to PCA52 : -0.08259022735453049\n",
      "PCA1 to PCA53 : -0.08259022735453049\n",
      "PCA1 to PCA54 : -0.08259022735453046\n",
      "PCA1 to PCA55 : -0.08259022735453048\n",
      "PCA1 to PCA56 : -0.08259022735453048\n",
      "PCA1 to PCA57 : -0.08259022735453049\n",
      "PCA1 to PCA58 : -0.08259022735453049\n",
      "PCA1 to PCA59 : -0.08259022735453046\n",
      "PCA1 to PCA60 : -0.08259022735453045\n",
      "PCA1 to PCA61 : -0.08259022735453048\n",
      "PCA1 to PCA62 : -0.08259022735453048\n",
      "PCA1 to PCA63 : -0.08259022735453048\n",
      "PCA1 to PCA64 : -0.08259022735453048\n",
      "PCA1 to PCA65 : -0.08259022735453045\n",
      "PCA1 to PCA66 : -0.08259022735453045\n",
      "PCA1 to PCA67 : -0.08259022735453046\n",
      "PCA1 to PCA68 : -0.08259022735453046\n"
     ]
    }
   ],
   "source": [
    "# CODE\n",
    "#Import Libraries\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA() #priciple components of X using sklearn.decomposition.PCA\n",
    "X_pca = pca.fit_transform(X)\n",
    "info='PCA1'\n",
    "i=1\n",
    "while i < len(X):\n",
    "    X_= X_pca[:,:i]\n",
    "    reg = LinearRegression().fit(X_, y) #fit linear regression\n",
    "    reg_=reg.coef_\n",
    "    print(info,\":\",reg_[0])\n",
    "    info = f'PCA1 to PCA{i+1}'\n",
    "    i += 1\n",
    "    if i == 69:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef8852e",
   "metadata": {},
   "source": [
    "State what you observe and explain the phenomenon in light of the correlation matrices of X and the PCs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863078d",
   "metadata": {},
   "source": [
    "### Explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa750db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           F1        F2        F3        F4        F5        F6        F7  \\\n",
      "F1   1.000000  0.913531  0.311943 -0.224226  0.128262 -0.666770 -0.183024   \n",
      "F2   0.913531  1.000000  0.317812 -0.258199  0.130520 -0.622469 -0.242818   \n",
      "F3   0.311943  0.317812  1.000000  0.177262 -0.143614 -0.293265  0.187043   \n",
      "F4  -0.224226 -0.258199  0.177262  1.000000 -0.132929  0.265029  0.293086   \n",
      "F5   0.128262  0.130520 -0.143614 -0.132929  1.000000 -0.358573 -0.285643   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "F64  0.098634  0.198664 -0.011620 -0.128655 -0.063090 -0.152410 -0.176422   \n",
      "F65  0.097466  0.189818 -0.055986 -0.163226 -0.032422 -0.175768 -0.276992   \n",
      "F66  0.073973  0.167800 -0.064956 -0.122116 -0.048134 -0.194564 -0.265044   \n",
      "F67  0.101065  0.191658 -0.057017 -0.152515 -0.014430 -0.216292 -0.252492   \n",
      "F68  0.096660  0.194582 -0.051986 -0.151291  0.001828 -0.185843 -0.220839   \n",
      "\n",
      "           F8        F9       F10  ...       F59       F60       F61  \\\n",
      "F1  -0.216161 -0.055840 -0.075897  ...  0.011411  0.014613  0.020654   \n",
      "F2  -0.259616 -0.067140 -0.108369  ...  0.043818  0.069341  0.117787   \n",
      "F3   0.049315  0.245557  0.152191  ... -0.013535 -0.042114 -0.036461   \n",
      "F4   0.182418  0.237123  0.082084  ... -0.087959 -0.095293 -0.059271   \n",
      "F5  -0.030005 -0.180035 -0.086214  ... -0.038236 -0.110004 -0.075233   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "F64 -0.148736 -0.132010 -0.129613  ...  0.218801  0.383667  0.490138   \n",
      "F65 -0.197861 -0.189361 -0.228585  ...  0.195358  0.358895  0.507822   \n",
      "F66 -0.229369 -0.264152 -0.294263  ...  0.125535  0.357088  0.493571   \n",
      "F67 -0.159271 -0.243804 -0.280377  ...  0.139522  0.337666  0.462011   \n",
      "F68 -0.087437 -0.127944 -0.148797  ...  0.136681  0.276637  0.374396   \n",
      "\n",
      "          F62       F63       F64       F65       F66       F67       F68  \n",
      "F1   0.027857  0.055047  0.098634  0.097466  0.073973  0.101065  0.096660  \n",
      "F2   0.126782  0.141524  0.198664  0.189818  0.167800  0.191658  0.194582  \n",
      "F3  -0.022306 -0.054106 -0.011620 -0.055986 -0.064956 -0.057017 -0.051986  \n",
      "F4  -0.062618 -0.122624 -0.128655 -0.163226 -0.122116 -0.152515 -0.151291  \n",
      "F5  -0.100387 -0.093432 -0.063090 -0.032422 -0.048134 -0.014430  0.001828  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "F64  0.563092  0.658770  1.000000  0.726183  0.654158  0.635232  0.557719  \n",
      "F65  0.557728  0.617803  0.726183  1.000000  0.743374  0.636269  0.599314  \n",
      "F66  0.573915  0.617408  0.654158  0.743374  1.000000  0.776078  0.677229  \n",
      "F67  0.551060  0.605311  0.635232  0.636269  0.776078  1.000000  0.754272  \n",
      "F68  0.431590  0.480959  0.557719  0.599314  0.677229  0.754272  1.000000  \n",
      "\n",
      "[68 rows x 68 columns]\n",
      "[[ 1.          0.1114772   0.21123498 ...  0.08727729  0.3524754\n",
      "  -0.06442269]\n",
      " [ 0.1114772   1.         -0.15732265 ... -0.39991937 -0.06579953\n",
      "  -0.50285714]\n",
      " [ 0.21123498 -0.15732265  1.         ...  0.09849664 -0.06978088\n",
      "   0.02120148]\n",
      " ...\n",
      " [ 0.08727729 -0.39991937  0.09849664 ...  1.          0.26730079\n",
      "   0.32182913]\n",
      " [ 0.3524754  -0.06579953 -0.06978088 ...  0.26730079  1.\n",
      "   0.16841614]\n",
      " [-0.06442269 -0.50285714  0.02120148 ...  0.32182913  0.16841614\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cor = X.corr()\n",
    "print(cor)\n",
    "\n",
    "\n",
    "cor1 = np.corrcoef(X_pca)\n",
    "print(cor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e8c46",
   "metadata": {},
   "source": [
    "From the correlation matrix of X we can observe that different features are significatly correlated. For example, the F1 and F2 features are highly correlated, And considering only one feature the coefficents was observed to be lower than compared to fitting with 2 features.We can say that the F1 is sensitive to addition of features. Therefore, when the number of features increases there is significant change in the coefficents with respect to the correlation between the features.\n",
    "\n",
    "From the correlation matrix of Principle components, we can observe that the correlation between the principle components is very low. From which we can interpret that there is no significant change in the coefficients with addition of principal components to the model. Therefore, there is no significant variation in the coefficients of PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b132d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
